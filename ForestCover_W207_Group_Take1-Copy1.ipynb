{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Initial Approach - ExtraTrees Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's grab for our ingredients to start making a delicious dish!\n",
      "Now, let's use some of our ingredients to create a wonderful mix!\n",
      "With our best magnifying glass, lets find the right combination of ingredients and get ready to bake!\n",
      "With the oven preheated and our ingredients ready, pop it in the oven!\n",
      "(565892,)\n",
      "Just need to cut our delicious baked good into slices...\n",
      "Ready to eat! (Be very careful! Contents hot!)\n",
      "Wait... how long did that take?\n",
      "... in 148.068s\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import pandas as pd \n",
    "import os \n",
    "import numpy as np\n",
    "from math import sqrt \n",
    " \n",
    "path = '/Users/jaredmaslin/Desktop/kaggle_forest_cover/' \n",
    "\n",
    " \n",
    "from time import time \n",
    "t0 = time() \n",
    "\n",
    " \n",
    "print \"Let's grab for our ingredients to start making a delicious dish!\" \n",
    "train_data = pd.read_csv(os.path.join(path,'train.csv'), header=0) \n",
    "train_labels = train_data['Cover_Type'].as_matrix() \n",
    "train_id = train_data['Id'].as_matrix() \n",
    "train_data.drop(['Cover_Type', 'Id'], axis=1, inplace=True) \n",
    "test_data = pd.read_csv(os.path.join(path,'test.csv'), header=0) \n",
    "test_id = test_data['Id'].as_matrix() \n",
    "test_data.drop(['Id'], axis=1, inplace=True)  \n",
    " \n",
    "print \"Now, let's use some of our ingredients to create a wonderful mix!\" \n",
    "\n",
    "#Azimuth Adjustment\n",
    "def adjust(x): \n",
    "    if x+180>360: \n",
    "        return x-180 \n",
    "    else: \n",
    "        return x+180 \n",
    "\n",
    "#Feature Engineering\n",
    "train_data['Aspect2'] = train_data.Aspect.map(adjust) \n",
    "test_data['Aspect2'] = test_data.Aspect.map(adjust) \n",
    "\n",
    "train_data['Above_Sea_Level'] = train_data.Vertical_Distance_To_Hydrology < 0 \n",
    "test_data['Above_Sea_Level'] = test_data.Vertical_Distance_To_Hydrology < 0 \n",
    "     \n",
    "train_data['Vertical_To_Water'] = train_data.Elevation-train_data.Vertical_Distance_To_Hydrology \n",
    "test_data['Vertical_To_Water'] = test_data.Elevation-test_data.Vertical_Distance_To_Hydrology \n",
    "\n",
    "train_data['Horizontal_To_Water'] = abs(train_data.Elevation-train_data.Horizontal_Distance_To_Hydrology*0.2)\n",
    "test_data['Horizontal_To_Water'] = abs(test_data.Elevation-test_data.Horizontal_Distance_To_Hydrology*0.2)\n",
    "      \n",
    "train_data['Pythagorean_To_Water'] = (train_data['Horizontal_Distance_To_Hydrology']**2+train_data['Vertical_Distance_To_Hydrology']**2)**0.5 \n",
    "test_data['Pythagorean_To_Water'] = (test_data['Horizontal_Distance_To_Hydrology']**2+test_data['Vertical_Distance_To_Hydrology']**2)**0.5 \n",
    " \n",
    "train_data['Water_And_Fire'] = train_data['Horizontal_Distance_To_Hydrology']+train_data['Horizontal_Distance_To_Fire_Points'] \n",
    "test_data['Water_And_Fire'] = test_data['Horizontal_Distance_To_Hydrology']+test_data['Horizontal_Distance_To_Fire_Points'] \n",
    " \n",
    "train_data['Water_Less_Fire'] = abs(train_data['Horizontal_Distance_To_Hydrology']-train_data['Horizontal_Distance_To_Fire_Points']) \n",
    "test_data['Water_Less_Fire'] = abs(test_data['Horizontal_Distance_To_Hydrology']-test_data['Horizontal_Distance_To_Fire_Points']) \n",
    "    \n",
    "train_data['Water_And_Roadway'] = (train_data['Horizontal_Distance_To_Hydrology']+train_data['Horizontal_Distance_To_Roadways']) \n",
    "test_data['Water_And_Roadway'] = (test_data['Horizontal_Distance_To_Hydrology']+test_data['Horizontal_Distance_To_Roadways']) \n",
    " \n",
    "train_data['Water_Less_Roadway'] = abs(train_data['Horizontal_Distance_To_Hydrology']-train_data['Horizontal_Distance_To_Roadways']) \n",
    "test_data['Water_Less_Roadway'] = abs(test_data['Horizontal_Distance_To_Hydrology']-test_data['Horizontal_Distance_To_Roadways']) \n",
    " \n",
    "train_data['Fire_And_Roadway'] = (train_data['Horizontal_Distance_To_Fire_Points']+train_data['Horizontal_Distance_To_Roadways']) \n",
    "test_data['Fire_And_Roadway'] = (test_data['Horizontal_Distance_To_Fire_Points']+test_data['Horizontal_Distance_To_Roadways']) \n",
    "\n",
    "train_data['Fire_Less_Roadway'] = abs(train_data['Horizontal_Distance_To_Fire_Points']-train_data['Horizontal_Distance_To_Roadways']) \n",
    "test_data['Fire_Less_Roadway'] = abs(test_data['Horizontal_Distance_To_Fire_Points']-test_data['Horizontal_Distance_To_Roadways']) \n",
    "\n",
    "\n",
    "train_matrix = train_data.as_matrix() \n",
    "test_X = test_data.as_matrix() \n",
    "n_features = int(sqrt(train_matrix.shape[1])) \n",
    " \n",
    "print \"With our best magnifying glass, lets find the right combination of ingredients and get ready to bake!\"  \n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=500, max_features = 0.3) \n",
    "clf = clf.fit(train_matrix, train_labels)\n",
    " \n",
    "print 'With the oven preheated and our ingredients ready, pop it in the oven!' \n",
    "predictions = clf.predict(test_X).astype(int) \n",
    "print predictions.shape \n",
    " \n",
    "print \"Just need to cut our delicious baked good into slices...\" \n",
    "prediction_write = open(os.path.join(path,\"sampleSubmission2.csv\"), \"wb\") \n",
    "open_file_object = csv.writer(prediction_write) \n",
    "open_file_object.writerow([\"Id\",\"Cover_Type\"]) \n",
    "open_file_object.writerows(zip(test_id, predictions)) \n",
    "prediction_write.close() \n",
    "print 'Ready to eat! (Be very careful! Contents hot!)' \n",
    "\n",
    "print 'Wait... how long did that take?'\n",
    "print(\"... in %0.3fs\" % (time() - t0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Follow-up Approach with ExtraTrees and AdaBoost (incl. additional features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's grab for our ingredients to start making a delicious dish!\n",
      "Now, let's use some of our ingredients to create a wonderful mix!\n",
      "With our best magnifying glass, lets find the right combination of ingredients and get ready to bake!\n",
      "With the oven preheated and our ingredients ready, pop it in the oven!\n",
      "(565892,)\n",
      "Just need to cut our delicious baked good into slices...\n",
      "Ready to eat! (Be very careful! Contents hot!)\n",
      "Wait... how long did that take?\n",
      "... in 186.722s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics \n",
    "from sklearn.grid_search import RandomizedSearchCV \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import preprocessing \n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "path = '/Users/jaredmaslin/Desktop/kaggle_forest_cover/' \n",
    "\n",
    "from time import time \n",
    "t0 = time() \n",
    "\n",
    "print \"Let's grab for our ingredients to start making a delicious dish!\" \n",
    "\n",
    "train_data = pd.read_csv(os.path.join(path,'train.csv'), header=0) \n",
    "train_labels = train_data['Cover_Type'].as_matrix() \n",
    "train_id = train_data['Id'].as_matrix() \n",
    "train_data.drop(['Cover_Type', 'Id'], axis=1, inplace=True) \n",
    "test_data = pd.read_csv(os.path.join(path,'test.csv'), header=0) \n",
    "test_id = test_data['Id'].as_matrix() \n",
    "test_data.drop(['Id'], axis=1, inplace=True)  \n",
    "\n",
    "\n",
    "print \"Now, let's use some of our ingredients to create a wonderful mix!\" \n",
    "\n",
    "#Azimuth Adjustment\n",
    "def adjust(x): \n",
    "    if x+180>360: \n",
    "        return x-180 \n",
    "    else: \n",
    "        return x+180 \n",
    "\n",
    "#Feature Engineering\n",
    "train_data['Aspect2'] = train_data.Aspect.map(adjust) \n",
    "test_data['Aspect2'] = test_data.Aspect.map(adjust) \n",
    "\n",
    "train_data['Energy'] = ((train_data['Hillshade_9am']+train_data['Hillshade_Noon'])/2)*10800 + ((train_data['Hillshade_Noon']+train_data['Hillshade_3pm'])/2)*10800\n",
    "test_data['Energy'] = ((test_data['Hillshade_9am']+test_data['Hillshade_Noon'])/2)*10800 + ((test_data['Hillshade_Noon']+test_data['Hillshade_3pm'])/2)*10800\n",
    "\n",
    "train_data.drop('Hillshade_9am', axis=1, inplace=True)\n",
    "test_data.drop('Hillshade_9am', axis=1, inplace=True)\n",
    "\n",
    "train_data.drop('Hillshade_Noon', axis=1, inplace=True)\n",
    "test_data.drop('Hillshade_Noon', axis=1, inplace=True)\n",
    "\n",
    "train_data.drop('Hillshade_3pm', axis=1, inplace=True)\n",
    "test_data.drop('Hillshade_3pm', axis=1, inplace=True)\n",
    "\n",
    "train_data['Above_Sea_Level'] = train_data.Vertical_Distance_To_Hydrology < 0 \n",
    "test_data['Above_Sea_Level'] = test_data.Vertical_Distance_To_Hydrology < 0 \n",
    "\n",
    "train_data['Vertical_To_Water'] = train_data.Elevation-train_data.Vertical_Distance_To_Hydrology \n",
    "test_data['Vertical_To_Water'] = test_data.Elevation-test_data.Vertical_Distance_To_Hydrology \n",
    "\n",
    "train_data['Horizontal_To_Water'] = train_data.Elevation-train_data.Horizontal_Distance_To_Hydrology*0.2 \n",
    "test_data['Horizontal_To_Water'] = test_data.Elevation-test_data.Horizontal_Distance_To_Hydrology*0.2 \n",
    "      \n",
    "train_data['Pythagorean_To_Water'] = (train_data['Horizontal_Distance_To_Hydrology']**2+train_data['Vertical_Distance_To_Hydrology']**2)**0.5 \n",
    "test_data['Pythagorean_To_Water'] = (test_data['Horizontal_Distance_To_Hydrology']**2+test_data['Vertical_Distance_To_Hydrology']**2)**0.5 \n",
    "\n",
    "train_data['Water_And_Fire'] = train_data['Horizontal_Distance_To_Hydrology']+train_data['Horizontal_Distance_To_Fire_Points'] \n",
    "test_data['Water_And_Fire'] = test_data['Horizontal_Distance_To_Hydrology']+test_data['Horizontal_Distance_To_Fire_Points'] \n",
    " \n",
    "train_data['Water_Less_Fire'] = abs(train_data['Horizontal_Distance_To_Hydrology']-train_data['Horizontal_Distance_To_Fire_Points']) \n",
    "test_data['Water_Less_Fire'] = abs(test_data['Horizontal_Distance_To_Hydrology']-test_data['Horizontal_Distance_To_Fire_Points']) \n",
    "\n",
    "train_data['Water_And_Roadway'] = abs(train_data['Horizontal_Distance_To_Hydrology']+train_data['Horizontal_Distance_To_Roadways']) \n",
    "test_data['Water_And_Roadway'] = abs(test_data['Horizontal_Distance_To_Hydrology']+test_data['Horizontal_Distance_To_Roadways']) \n",
    " \n",
    "train_data['Water_Less_Roadway'] = abs(train_data['Horizontal_Distance_To_Hydrology']-train_data['Horizontal_Distance_To_Roadways']) \n",
    "test_data['Water_Less_Roadway'] = abs(test_data['Horizontal_Distance_To_Hydrology']-test_data['Horizontal_Distance_To_Roadways']) \n",
    " \n",
    "train_data['Fire_And_Roadway'] = abs(train_data['Horizontal_Distance_To_Fire_Points']+train_data['Horizontal_Distance_To_Roadways']) \n",
    "test_data['Fire_And_Roadway'] = abs(test_data['Horizontal_Distance_To_Fire_Points']+test_data['Horizontal_Distance_To_Roadways']) \n",
    "\n",
    "train_data['Fire_Less_Roadway'] = abs(train_data['Horizontal_Distance_To_Fire_Points']-train_data['Horizontal_Distance_To_Roadways']) \n",
    "test_data['Fire_Less_Roadway'] = abs(test_data['Horizontal_Distance_To_Fire_Points']-test_data['Horizontal_Distance_To_Roadways']) \n",
    "\n",
    "train_data['Is_Roadway_Closer_than_Water'] = (train_data['Horizontal_Distance_To_Roadways'] < train_data['Horizontal_Distance_To_Hydrology'])\n",
    "test_data['Is_Roadway_Closer_than_Water'] = (test_data['Horizontal_Distance_To_Roadways'] < test_data['Horizontal_Distance_To_Hydrology'])\n",
    "\n",
    "train_data['Is_Firepoint_Closer_than_Water'] = (train_data['Horizontal_Distance_To_Fire_Points'] < train_data['Horizontal_Distance_To_Hydrology'])\n",
    "test_data['Is_Firepoint_Closer_than_Water'] = (test_data['Horizontal_Distance_To_Fire_Points'] < test_data['Horizontal_Distance_To_Hydrology'])\n",
    "\n",
    "train_matrix = train_data.as_matrix() \n",
    "test_X = test_data.as_matrix() \n",
    "n_features = int(sqrt(train_matrix.shape[1])) \n",
    " \n",
    "print \"With our best magnifying glass, lets find the right combination of ingredients and get ready to bake!\"  \n",
    "\n",
    "#clf = ExtraTreesClassifier()   \n",
    "#clf = clf.fit(train_matrix, train_labels) \n",
    "#param_grid = { \n",
    "    #\"n_estimators\" : sp_randint(10, 1000), \n",
    "    #\"max_features\": sp_randint(0,20), \n",
    "    #\"min_samples_leaf\": sp_randint(1,10), \n",
    "    #\"min_samples_split\": sp_randint(1,10), \n",
    "    #\"criterion\": [\"gini\", \"entropy\"], \n",
    "#} \n",
    "\n",
    "#grid_search = RandomizedSearchCV(clf, n_iter=20, param_distributions=param_grid) \n",
    "#grid_search.fit(train_matrix, train_labels) \n",
    "#best_parameters = grid_search.best_params_ \n",
    "\n",
    "#the following parameters are good  \n",
    "#best_parameters = {'n_estimators' : 35, 'max_features' : 17, 'min_samples_split' : 3, \\ \n",
    "#'min_samples_leaf' : 3, 'bootstrap' : False, 'criterion': \"entropy\"} \n",
    "\n",
    "#print best_parameters \n",
    "\n",
    "#clfa = ExtraTreesClassifier(n_estimators = 858, max_features = 7, min_samples_leaf = 1, min_samples_split = 2, criterion = 'entropy') \n",
    "clfa = ExtraTreesClassifier(n_estimators = 600, max_features = 0.3)\n",
    "\n",
    "clf = AdaBoostClassifier(clfa, n_estimators = 600) \n",
    " \n",
    "clf = clf.fit(train_matrix, train_labels)\n",
    " \n",
    "print 'With the oven preheated and our ingredients ready, pop it in the oven!'\n",
    " \n",
    "predictions = clf.predict(test_X).astype(int) \n",
    "print predictions.shape \n",
    " \n",
    "print \"Just need to cut our delicious baked good into slices...\" \n",
    "\n",
    "prediction_write = open(os.path.join(path,\"sampleSubmissionGSCV_New1.csv\"), \"wb\") \n",
    "open_file_object = csv.writer(prediction_write) \n",
    "open_file_object.writerow([\"Id\",\"Cover_Type\"]) \n",
    "open_file_object.writerows(zip(test_id, predictions)) \n",
    "prediction_write.close() \n",
    "print 'Ready to eat! (Be very careful! Contents hot!)'  \n",
    "\n",
    "print 'Wait... how long did that take?'\n",
    "\n",
    "print(\"... in %0.3fs\" % (time() - t0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
